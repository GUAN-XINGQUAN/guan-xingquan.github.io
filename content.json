{"meta":{"title":"Guan's Website","subtitle":"","description":"","author":"Xingquan Guan","url":"http://example.com","root":"/"},"pages":[{"title":"About Me","date":"2021-03-07T18:48:42.000Z","updated":"2021-03-08T07:30:11.066Z","comments":true,"path":"About/index.html","permalink":"http://example.com/About/index.html","excerpt":"","text":"Education 2009-2013 &emsp; B.Sc. in Civil Engineering &emsp; Huazhong University of Science and Technology 2013-2016 &emsp; M.Sc. in Structural Engineering &emsp; Huazhong University of Science and Technology 2016-2020 &emsp; M.Sc. in Earthquake Engineering &emsp; University of California, Los Angeles 2016-2021 &emsp; Ph.D. in Structural/Earthquake Engineering &emsp; University of California, Los Angeles &emsp;&emsp;"},{"title":"Blog","date":"2021-03-07T19:06:00.000Z","updated":"2021-03-10T08:04:44.378Z","comments":true,"path":"Blog/index.html","permalink":"http://example.com/Blog/index.html","excerpt":"","text":"Using “Download Note” for better readability. Blogs for Statistics: Linear Regression: Online Reading Download Note Logistic Regression: Online Reading Download Note Blogs for Structural Engineering: Modeling parameters for steel beam using IMK material:Online Reading Download Note Modeling parameters for steel column using IMK material: Online Reading Download Note"},{"title":"Photo/Video Gallery","date":"2021-03-07T19:06:39.000Z","updated":"2021-03-15T04:38:22.407Z","comments":true,"path":"Photo-Video-Gallery/index.html","permalink":"http://example.com/Photo-Video-Gallery/index.html","excerpt":"","text":"I am a beginner in playing guitar. Here are some songs played by me (link to YouTube): The Path to Ordinary (Chinese Song) Lilac (Chinese Song) Someone You Loved"},{"title":"Publications","date":"2022-05-30T04:43:49.000Z","updated":"2022-05-30T04:37:52.575Z","comments":true,"path":"Publications/index.html","permalink":"http://example.com/Publications/index.html","excerpt":"","text":"Journal Publications (* corresponding author): Zeng, Z., Zhu, Z., Yao, W., Wang, Z., Wang, C., Wei, Y.*, Wei, Z., &amp; Guan, X. (2022)Accurate prediction of concrete compressive strength based on explainable features using deep learning. Construction and Building Materials, 329, 127082. Guan, X.*, Burton, H., Shokrabadi, M., &amp; Yi, Z. (2021). Seismic drift demand estimation for SMF buildings: from mechanistic to data-driven models. Journal of Structural Engineering. Journal of Structural Engineering, 147(6), 04021058. (3-minute video synopsis) Gao, F., Liu, Z., &amp; Guan, X.* (2021). Fire resistance behavior of T-stub joint components under transient heat transfer conditions. Engineering Structures. 237, 112164. Guan, X.*, Burton, H., &amp; Shokrabadi, M. (2020). A database of seismic designs, nonlinear models, and seismic responses for steel moment resisting frame buildings. Earthquake Spectra. 8755293020971209. (3-minute video synopsis) Guan, X.*, Burton, H., &amp; Sabol, T. (2020). Python-based computational platform to automate seismic design, nonlinear structural model construction and analysis of steel moment resisting frames. Engineering Structures, 224, 111199.(3-minute video synopsis) Guan, X.*, Burton, H., &amp; Moradi, S. (2018). Seismic performance of a self-centering steel moment frame building: from component-level modeling to economic loss assessment. Journal of Constructional Steel Research, 150, 129-140. Gao, F., Tang, Z., Guan, X.*, Zhu, H., &amp; Chen, Z. (2018). [Ultimate strength of tubular T-joints reinforced with doubler plates after fire exposure](Ultimate strength of tubular T-joints reinforced with doubler plates after fire exposure - ScienceDirect). Thin-Walled Structures, 132, 616-628. Gao, F., Guan, X.*, Zhu, H., &amp; Ye, Y. (2018). Fire-resistance behavior of completely overlapped tubular joints under lap brace axial loading. Journal of Structural Engineering, 144(9), 04018137. Mohamed, H.S.*, Gao, F., Guan, X., &amp; Zhu, H. (2018). Experimental investigation on the fatigue behavior of heat-treated tubular T-joints. KSCE Journal of Civil Engineering, 22, 2451-2463. Gao, F.*, Guan, X., Zhu, H., &amp; Liu, X. (2015). Fire resistance behavior of tubular T-joints reinforced with collar plates. Journal of Constructional Steel Research, 115, 106-120. Gao, F.*, Guan, X., Zhu, H., &amp; Xia, Y. (2015). [Hysteretic behavior of tubular T-joints reinforced with doubler plates after fire exposure](Hysteretic behaviour of tubular T-joints reinforced with doubler plates after fire exposure - ScienceDirect). Thin-Walled Structures, 92, 10-20. Conference Presentations Guan, X. &amp; Burton, H. Collaborative filtering-based collapse fragility assessment. 12th U.S. National Conference on Earthquake Engineering, Salty Lake City, U.S.A., June 2022. (12NCEE Registration Grant Recipient) Guan, X. &amp; Burton, H. A comparative assessment of mechanistic and data-driven models to estimate building responses. 17 World Conference on Earthquake Engineering, Sendai, Japan, September 2021. Guan, X. &amp; Burton, H. A Python-based platform to automate seismic design and nonlinear analysis of steel moment frames. 17th World Conference on Earthquake Engineering, Sendai, Japan, September 2021. Burton, H. &amp; Guan, X. The case for incorporating artificial intelligence and automation in performance-based seismic design. 2020 SEAOC Convention. Maui, U.S.A., December 2020. Guan, X., Moradi, S., &amp; Burton, H. Seismic performance of a self-centering steel moment frame building. 11th U.S. National Conference on Earthquake Engineering, Los Angeles, U.S.A., June 2018. Gao, F., Guan, X. &amp; Zhu, H. Parametric study on hysteretic behavior of doubler plate-reinforced tubular T-joints after fire exposure. 13th International Symposium on Structural Engineering. Hefei, China, October 2014."},{"title":"Research","date":"2021-03-07T08:52:30.000Z","updated":"2021-03-13T01:57:06.003Z","comments":true,"path":"Research/index.html","permalink":"http://example.com/Research/index.html","excerpt":"","text":"Fire Resistance Behavior of Welded Tubular Structures​ Welded tubular structures have been widely used in large-span structures, such as stadiums, television towers, airport terminals, and jacket offshore platforms. In these structures, tubular joints serve as key components because they feature high stress concentrations. The fact that steel material is highly sensitive to high temperatures makes the tubular joints vulnerable under fire conditions. The relevant design guidelines (such as CIDECT and Eurocode 3) provide limited details on the performance of these joints at elevated temperatures. To understand the response of tubular structures throughout the entire fire process, a series of experiments, numerical simulations, and theoretical derivations were conducted. Based on this project, a finite-element simulation platform was developed in ABAQUS to accurately capture the structural response of joints. Moreover, a series of empirical equations were proposed to predict the critical temperatures for joints with various geometric configurations. Experimental setup Finite element simulation Performance-Based Analytics-Driven Seismic Design of Steel Moment Frame Buildings​ With the embrace of the performance-based seismic design as the state-of-the-art design method, recent emphasis has been placed on eliminating its drawbacks and facilitating its application in practice. This project aims to propose an alternative design method: performance-based analytics-driven seismic design, which is applied to steel moment resisting frame (SMRF) buildings. In this project, a Python-based computational platform was developed to automate the seismic design, structural modeling, and seismic response simulation. Then a comprehensive database including more than 600 SMRF designs and their responses are constructed. Using the database, three machine learning-based data-driven models are developed to estimate the seismic drift demand in SMRFs and the efficacy of newly-developed and existing model is investigated. Finally, a set of surrogate models are created to estimate the probabilistic distribution of engineering demand parameters, which are further adopted to evaluate the earthquake-induced economic losses."},{"title":"Resources","date":"2021-03-07T19:06:25.000Z","updated":"2021-03-11T20:20:10.943Z","comments":true,"path":"Resources/index.html","permalink":"http://example.com/Resources/index.html","excerpt":"","text":"Automated Seismic Design and Analysis Platform (AutoSDA): Overview of AutoSDA platform AutoSDA platform is a Python-based computational developed by me. This platform automates the seismic design, nonlinear model construction, and seismic response simulation for steel moment resisting frames. The download link is here. It has also been implement in EE-UQ (Earthquake Engineering with Uncertainty Quantification) developed by National Science Foundation Hazards Engineering Research Infrastructure (NHERI) SimCenter. The detailed explanation for this platform could be found in this paper. Useful Links:Our research group YouTube channel: Burton Research Group at UCLA - YouTube"},{"title":"Teaching","date":"2021-03-07T08:10:52.000Z","updated":"2021-03-07T08:50:11.175Z","comments":true,"path":"Teaching/index.html","permalink":"http://example.com/Teaching/index.html","excerpt":"","text":"As a Teaching Fellow at the University of California, Los Angeles, I have taught the following courses: Course &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Time CHIN 2 Elementary Modern Chinese &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Winter 2021 CHIN 1 Elementary Modern Chinese &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Fall 2020 C&amp;EE 241 Advanced Steel Structures &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Spring 2020 C&amp;EE 235 Advanced Structural Analysis &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Fall 2019 C&amp;EE 241 Advanced Steel Structures &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Spring 2019 C&amp;EE 235 Advanced Structural Analysis &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Fall 2018 C&amp;EE 144 Structural System Design &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Spring 2018"}],"posts":[{"title":"Hello World","slug":"hello-world","date":"2022-05-29T23:21:17.808Z","updated":"2021-03-06T22:04:08.032Z","comments":true,"path":"2022/05/29/hello-world/","link":"","permalink":"http://example.com/2022/05/29/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"News and Updates","slug":"News-and-Updates","date":"2022-05-29T07:01:45.000Z","updated":"2022-05-30T03:36:34.500Z","comments":true,"path":"2022/05/29/News-and-Updates/","link":"","permalink":"http://example.com/2022/05/29/News-and-Updates/","excerpt":"","text":"News and Updates:March 17, 2022: I started a new quest as a senior data scientist at ZEST AI. I will use my expertise to help decision making in finance world. May 1, 2021: I started my new journey as a postdoctoral scholar at UCLA. I am working with Prof. Henry Burton and Prof. Yousef Bozorgnia. March 16, 2021: My Ph.D. dissertation was approved by all doctoral committee members and the UCLA graduation division. I have met all the doctoral degree requirements. Officially I became a Ph.D. March 3, 2021: I passed Ph.D. final defense exam at the University of California, Los Angeles. My dissertation title is “Performance-based analytics-driven seismic design of steel moment frame buildings”.","categories":[],"tags":[{"name":"news","slug":"news","permalink":"http://example.com/tags/news/"}]},{"title":"Introduction","slug":"Introduction","date":"2022-05-29T05:10:51.000Z","updated":"2022-05-30T05:03:37.857Z","comments":true,"path":"2022/05/28/Introduction/","link":"","permalink":"http://example.com/2022/05/28/Introduction/","excerpt":"","text":"Brief IntroductionHi there! My name is Xingquan Guan and I’m a Senior Data Scientist at ZEST AI. I received my Ph.D. in Structural Engineering with a Minor in Statistics and Computer Science at the University of California, Los Angeles. My expertise is to apply artificial intelligence in solving engineering related problems. Particularly, my research interests include: Application of artificial intelligence in enhancing community resilience Experimental test and finite element analysis of building structures under extreme loading Adoption of novel devices to improve seismic performance of conventional structures Development of advanced computational simulation platforms for design automation","categories":[],"tags":[]},{"title":"Updated Modeling parameters for steel columns using IMK","slug":"Updated-Modeling-parameters-for-steel-columns-using-IMK","date":"2021-03-10T06:07:20.000Z","updated":"2021-03-10T06:27:10.479Z","comments":true,"path":"2021/03/09/Updated-Modeling-parameters-for-steel-columns-using-IMK/","link":"","permalink":"http://example.com/2021/03/09/Updated-Modeling-parameters-for-steel-columns-using-IMK/","excerpt":"","text":"Updated Steel Column Hinge ModelingReference:[1]: Beam column hinge modeling summarized by GUAN [2]: Proposed updates to the ASCE 41 nonlinear modeling parameters for wide-flange steel columns in support performance-based seismic engineering Background:The file “Beam column hinge modeling summarized by GUAN” has summarized the findings for beam hinge modeling reported by Lignos. It says “until more experiments are conducted, the equations provided in the study could be used for columns”. More recently, the modeling for column hinge has been updated and is summarized in this file. Modified IMK considers three types of deteriorations: basic strength, post-peak strength, and unloading stiffness. The reloading stiffness deterioration is not reflected. Equations for parameters Limitations are listed below: Column section size is between W12 to W36. 3.71 &lt;= h/tw &lt;= 57.5 38.4 &lt;= Lb/ry &lt;= 120 0.0 &lt;= Pg/Pye &lt;= 0.75 Steel section is made up of ASTM A992 Gr. 50 Steel. Pre-capping plastic rotation: Monotonic backbone:$$\\theta_p = 294 \\cdot (\\frac{h}{t_w})^{-1.7} \\cdot (\\frac{L_b}{r_y})^{-0.7} \\cdot (1-\\frac{P_g}{P_{ye}})^{1.6} \\leq 0.20\\ rad$$First-cycle envelope:$$\\theta_p^*=15 \\cdot (\\frac{h}{t_w})^{-1.6} \\cdot (\\frac{L_b}{r_y})^{-0.3} \\cdot (1-\\frac{P_g}{P_{ye}})^{2.3} \\leq 0.10 rad$$ Post-capping plastic rotation: Monotonic backbone:$$\\theta_{pc} = 90 \\cdot (\\frac{h}{t_W})^{-0.8} \\cdot (\\frac{L_b}{r_y})^{-0.5} \\cdot (1-\\frac{P_g}{P_{ye}}) \\leq 0.30\\ rad$$First-cycle envelope:$$\\theta_{pc}^* = 14 \\cdot (\\frac{h}{t_w})^{-0.8} \\cdot (\\frac{L_b}{r_y})^{-0.5} \\cdot (1-\\frac{P_g}{P_{ye}}) \\leq 0.10\\ rad$$ Reference cumulative plastic rotation:$$\\Lambda_s = 255000 \\cdot (\\frac{h}{t_w})^{-2.14} \\cdot (\\frac{L_b}{r_y})^{-0.53} \\cdot (1-\\frac{P_g}{P_{ye}})^{4.92}\\leq \\ 3.0,\\quad \\textrm{if}\\ P_g/P_{ye} \\leq \\ 0.35 \\ \\Lambda_s = 268000 \\cdot (\\frac{h}{t_w})^{-2.30} \\cdot (\\frac{L_b}{r_y})^{-1.30} \\cdot (1-P_g/P_{ye})^{1.19} \\leq\\ 3.0,\\quad \\textrm{if}\\ P_g/P_{ye} &gt; 0.35\\ \\Lambda_k = \\Lambda_c = 0.9 \\cdot \\Lambda_s$$ Effective yield strength: $$M_y = M_y^* = 1.15 \\cdot Z \\cdot R_y \\cdot F_{yn} \\cdot (1-\\frac{P_g}{2P_{ye}})\\quad \\textrm{if}\\ P_g/P_{ye} &lt; 0.20\\My = M_y^* = 1.15 \\cdot Z \\cdot Ry \\cdot F_{yn} \\cdot \\frac{9}{8}(1-\\frac{P_g}{P_{ye}})\\quad \\textrm{if}\\ P_g/P_{ye} \\geq 0.20$$ Residual strength ratio: Monotonic backbone:$$k = M_r/M_y = (0.5-0.4\\cdot{P_g}{P_{ye}})$$First-cycle envelope:$$k = M_r^*/M_y^* = (0.4-0.4\\cdot\\frac{P_g}{P_ye})\\cdot M_y^*$$ Ultimate rotation capacity: Monotonic backbone:$$\\theta_{ult} = 0.15$$First-cycle envelope:$$\\theta_{ult}^* = 0.08 \\cdot (1-0.6\\cdot\\frac{P_g}{P_{ye}})$$ Peak flexural strength: Monotonic backbone:$$M_{max} = a \\cdot M_y\\a = 12.5 \\cdot (\\frac{h}{t_w})^{-0.2} \\cdot (\\frac{L_b}{r_y})^{-0.4} \\cdot (1-\\frac{P_g}{P_{ye}})^{0.4},\\quad 1.0 \\leq a \\leq 1.3$$First-cycle envelope:$$a^* = 9.5 \\cdot(\\frac{h}{t_w})^{-0.4} \\cdot (\\frac{L_b}{r_y})^{-0.16} \\cdot (1-\\frac{P_g}{P_{ye}})^{0.2}\\quad 1.0 \\leq a \\leq 1.3$$ Effective yield rotation:$$\\theta_y = M_y / K_e$$ Elastic stiffness:$$K_e = L^2K_sK_b/[2(K_s+K_b)]\\K_s = GA_w/L\\K_b = 12EI/L^3$$ In all equations above, Pg is the gravity-induced compressive load. Pye is the axial yield strength and is calculated based on expected steel material properties. Fyn is the nominal yield stress of steel material. OpenSees IMK material model","categories":[],"tags":[]},{"title":"Modeling parameters for steel beams using IMK","slug":"Modeling-parameters-for-steel-beams-using-IMK","date":"2021-03-10T05:50:40.000Z","updated":"2021-03-10T06:27:26.059Z","comments":true,"path":"2021/03/09/Modeling-parameters-for-steel-beams-using-IMK/","link":"","permalink":"http://example.com/2021/03/09/Modeling-parameters-for-steel-beams-using-IMK/","excerpt":"","text":"Steel Beam Hinge ModelingReference:[1]: Hysteretic models that incorporate strength and stiffness deterioration [2]: Deterioration modeling of steel components in support of collapse prediction of steel moment frames under earthquake loading [3]: Global collapse of frame structures under seismic excitations [4]: Sidesway collapse of deteriorating structural systems under seismic excitations Modeling introduction No deterioration exits: Three parameters: initial stiffness Ke; yield strength Fy; strain-hardening stiffness Ks$$K_s = \\alpha_sK_e$$ Consider deterioration: Apart from above three parameters; cap deformation deltac; peak strength Fc; Post-capping stiffness Kc; residual strength Fr $$K_s = \\alpha_s K_e \\K_c = \\alpha_c K_c \\F_r = \\lambda F_y$$ Four types of deterioration involved in strength and stiffness deterioration: basic strength; post-capping strength, unloading stiffness, and accelerated reloading stiffness deteriorations. Modeling parametersReference 2 provides a set of equations to calculate modeling parameters Trend of modeling parameters Generally, modeling parameters for beams with other-than-RBS are smaller than that with RBS connection. Dispersion of modeling parameters for beams with RBS connection are smaller. Modeling parameters decrease as beam depth increases. $\\theta_p$ is linearly proportional to beam shear span L (distance from plastic hinge location to point of inflection) Providing lateral bracing close to RBS portion of a beam decreases the rate of cyclic deterioration. For most deep beam, small bf/2tf ratio has detrimental effect on theta_p, but benefits the parameters theta_pc and \\LAMBDA. h/tt is very important for all three modeling parameters (\\theta_p, \\theta_pc, \\LAMBDA). Equations for parameters Database for the equations: Set 1: Beams with other-than-RBS connections and depth 18 in. &lt;= d &lt;= 36 in. Set 2: Beams with RBS connections and depth 18 in &lt;= d &lt;= 36 in Set 3: Beams with other-than-RBS connections and depth d &gt;= 21 in. Set 4: Beams with RBS connections and depth &gt;= 21 in. Sets 2 and 4 do not differ too much!!! Pre-capping plastic rotation: Data set 1:$$\\theta_p = 0.0865 \\cdot (\\frac{h}{t_w})^{-0.365} \\cdot (\\frac{b_f}{2 \\cdot t_f})^{-0.140} \\cdot (\\frac{L}{d})^{0.340} \\cdot (\\frac{c_{unit}^1 \\cdot d}{533})^{-0.721} \\cdot (\\frac{c_{unit}^2 \\cdot F_y}{355})^{-0.230}$$If millimeters and megapascals are used:$$c_{unit}^1 = c_{unit}^2 = 1.0$$If depth is in inches and Fy is in ksi:$$c_{unit}^1 = 25.4\\c_{unit}^2 = 6.895$$Data set 3:$$\\theta_p = 0.318 \\cdot (\\frac{h}{t_w})^{-0.550} \\cdot (\\frac{b_f}{2 \\cdot t_f})^{-0.345} \\cdot (\\frac{L_b}{r_y})^{-0.0230} \\cdot (\\frac{L}{d})^{0.090} \\cdot (\\frac{c_{unit}^1 \\cdot d}{533})^{-0.330} \\cdot (\\frac{c_{unit}^2 \\cdot F_y}{355})^{-0.130}$$Data set 2:$$\\theta_p = 0.19 \\cdot (\\frac{h}{t_w})^{-0.314} \\cdot (\\frac{b_f}{2 \\cdot t_f})^{-0.100} \\cdot (\\frac{L_b}{r_y})^{-0.185} \\cdot (\\frac{L}{d})^{0.113} \\cdot (\\frac{c_{unit}^1 \\cdot d}{533})^{-0.760} \\cdot (\\frac{c_{unit}^2 \\cdot F_y}{355})^{-0.070}$$ Post-capping plastic rotation: Data set 1:$$\\theta_{pc} = 5.63 \\cdot (\\frac{h}{t_w})^{-0.565} \\cdot (\\frac{b_f}{2 \\cdot t_f})^{-0.800} \\cdot (\\frac{c_{unit}^1 \\cdot d}{533})^{-0.280} \\cdot (\\frac{c_{unit}^2 \\cdot F_y}{355})^{-0.430}$$Data set 3:$$\\theta_{pc} = 7.50 \\cdot (\\frac{h}{t_w})^{-0.610} \\cdot (\\frac{b_f}{2 \\cdot t_f})^{-0.710} \\cdot (\\frac{L_b}{r_y})^{-0.110} \\cdot (\\frac{c_{unit}^1 \\cdot d}{533})^{-0.161} \\cdot (\\frac{c_{unit}^2 \\cdot F_y}{355})^{-0.320}$$Data set 2:$$\\theta_{pc} = 9.52 \\cdot (\\frac{h}{t_w})^{-0.513} \\cdot (\\frac{b_f}{2 \\cdot t_f})^{-0.863} \\cdot (\\frac{L_b}{r_y})^{-0.108} \\cdot (\\frac{c_{unit}^2 \\cdot F_y}{355})^{-0.360}$$ Reference cumulative plastic rotation: Data set 1:$$\\Lambda = \\frac{E_t}{M_y} = 495 \\cdot (\\frac{h}{t_w})^{-1.34} \\cdot (\\frac{b_f}{2 \\cdot t_f})^{-0.595} \\cdot (\\frac{c_{unit}^2 \\cdot F_y}{355})^{-0.360}$$Data set 3:$$\\Lambda = \\frac{E_t}{M_y} = 536 \\cdot (\\frac{h}{t_w})^{-1.26} \\cdot (\\frac{b_f}{2 \\cdot t_f})^{-0.525} \\cdot (\\frac{L_b}{r_y})^{-0.130}\\cdot (\\frac{c_{unit}^2 \\cdot F_y}{355})^{-0.291}$$Data set 2:$$\\Lambda = \\frac{E_t}{M_y} = 585 \\cdot (\\frac{h}{t_w})^{-1.14} \\cdot (\\frac{b_f}{2 \\cdot t_f})^{-0.632} \\cdot (\\frac{L_b}{r_y})^{-0.205} \\cdot (\\frac{c_{unit}^2 \\cdot F_y}{355})^{-0.391}$$ Remarks: The range of validity of these equations is only as good as the experimental data allows it to be. Though the data does not include heavy W14 sections (heavier than W14X370) and heavy (heavier than W36X150) and deep (deeper than W36) beam sections. Predictions from regression equations were compared with existing heavy W14 sections and found to provide reasonable close values of experimentally obtained parameters. **Until more experiments are conducted, the preceding equations provide the best estimates that can be offered to columns. ** Effective yield strength My: It is found to be slightly greater than predicted bending strength My,p, which is defined as plastic section modulus Z times the measured material yield strength. For RBS, the ratio of My to My,p is 1.06, whereas for non-RBS is 1.17. Residual strength ratio k: From the data sets for W-sections, a residual strength ratio k = Mr/My of approximately 0.4 is suggested for sets 3 and 4. To assess it more reliably, more experiments with very large deformation cycles need to be conducted. Ultimate rotation capacity $\\theta_u$: This quantity is highly dependent on loading history and my be very large for cases in which only a few very large cycles are executed. Estimation regarding this parameter are made only for experiments with stepwise increasing cycles of the type required in AISC. For other than RBS, it is 0.05 to 0.06 rad. For RBS, it is 0.06 to 0.07 rad. For monotonic loading, \\theta_u is found to be on the order of three times as large as the \\theta_u reported in symmetric cyclic loading protocols. OpenSees IMK material modelReference: OpenSees IMK material model Elastic stiffness K0:$$K_0 = (n+1) \\frac{6 \\cdot E \\cdot I_z}{L}$$where E, I and L are elastic modulus, moment of inertia, and length of beam. Typically, n is set as 10. Strain hardening ratio for positive (negative) directions: Will be computed at he very end of this note. Effective yield strength My: According to findings reported in Ref [2], for beams with RBS connection:$$My = 1.06 \\cdot M_{y,p} = 1.06 \\cdot Z \\cdot F_y$$ Cyclic deterioration for basic strength, post-capping strength, accelerated reloading stiffness, and unloading stiffness.$$\\begin{align}&amp;\\Lambda_S: \\rm {basic\\ strength}\\&amp;\\Lambda_C: \\rm {post-capping\\ strength}\\&amp;\\Lambda_A: \\rm {accelerated\\ reloading\\ stiffness}\\&amp;\\Lambda_K: \\rm {unloading\\ stiffness}\\end{align}$$A very large number means almost no cyclic deterioration. In my modeling$$\\begin{align}&amp;\\Lambda_K=\\Lambda_A=\\Lambda_S = \\Lambda_C = (n+1) \\cdot \\Lambda = 11 \\cdot \\Lambda\\end{align}$$Where $\\Lambda$ is calculated from regression equation in preceding section. Rate of deterioration for basic strength, post-capping strength, accelerated reloading, and unloading stiffness. By default: (In my modeling)$$\\begin{align}&amp; c_S = 1.0\\&amp; c_C = 1.0\\&amp; c_A = 1.0\\&amp; c_K = 1.0\\\\end{align}$$ Plastic rotation capacity theta_p In my modeling, use the regression equation in the preceding section. Post-capping rotation capacity theta_pc: In my modeling, use the regression equation in the preceding section. Residual strength ratio Res: Based on Ref [2], the ratio is assumed to be 0.4. Ultimate rotation theta_u: Based on preceding section and official OpenSees example, it is assumed to be 0.4. Ultimate rotation is associated with the failure of ductile tearing. Ref [4] reveals that ductile tearing will not be critical in most of cases. In my modeling, use 0.4. Rate of cyclic deterioration D (for symmetric hysteretic response use 1.0): In my modeling, use 1.0. elastic stiffness amplification factor nFactor: This is optional, default value is 0. In my modeling, ignore this argument and the program would automatically use 0. Strain hardening ratio from Official OpenSees example For elastic beam-column element, modified moment of inertia is:$$I_{mod} = \\frac{n+1.0}{n} \\cdot I_z$$Rotational stiffness for elastic beam-column element:$$K_{bc} = \\frac{n+1}{n} \\cdot \\frac{6 \\cdot E \\cdot I_z}{L}$$ Initial stiffness for rotational spring for beam: $$K_s = n \\cdot \\frac{6 \\cdot E \\cdot I_{mod}}{L} = (n+1.0) \\cdot \\frac{6 \\cdot E \\cdot I_z}{L}$$ ​ where Iz is the moment of inertia for beam section. ​ Strain hardening ratio for spring:$$a_{mem} = (n+1.0) \\cdot \\frac{My \\cdot (M_c/M_y - 1.0)}{\\theta_p} \\cdot \\frac{1}{K_s}$$ ​ Modified strain hardening ratio for spring (used for modeling):$$b = \\frac{a_{men}}{1+n \\cdot (1 - a_{men})}$$ Strain hardening ratio from Prof. Burton’s codes: Initial stiffness for rotational spring for beam:$$K = n_1 \\cdot K_0 = 11 \\cdot \\frac{6 \\cdot E \\cdot I_z}{L}$$Straining hardening ratio for spring:$$asPosScaled = \\frac{a_s}{1+n_2 \\cdot (1- a_s)}$$Where n2 = 10. as is calculated using the following equation:$$a_s = 0.11 \\cdot \\frac{My}{\\theta_p} \\cdot \\frac{1}{K_0}\\{K_0} = \\frac{6 \\cdot E \\cdot I_z}{L}$$","categories":[{"name":"Blog","slug":"Blog","permalink":"http://example.com/categories/Blog/"}],"tags":[]},{"title":"Week 2 Logistic Regression","slug":"Week-2-Logistic-Regression","date":"2021-03-09T18:11:00.000Z","updated":"2021-03-09T18:15:23.592Z","comments":true,"path":"2021/03/09/Week-2-Logistic-Regression/","link":"","permalink":"http://example.com/2021/03/09/Week-2-Logistic-Regression/","excerpt":"","text":"————————————— start from here ——————————————- Background (问题背景): Let’s consider a binary classification. For example, students are going to apply for student loan from a financial institution. The instution decides whether it will approve the student application based on two factors: the student’s credit score and his/her monthly income. Now we can use $X1$ to represent the student’s monthly income and $X2$ to represent the student’s credit score. Then we can use $Y \\in {1,0}$ to denote the application results. $Y_i=1$ means that the institution approves the student’s application and 0 for the reject of application. Imagine that we have 100 students who will apply for the student loan. Obviously, some of them can get the load whereas others get rejected. To model this problem, we can use logistic regression to classify the students who can and who cannot get the loan. $X1$ and $X2$ are two column vectors with the length of 100. Y is a column vector whose length is also 100. Each element in Y can either be 1 or 0. 我们现在来考虑一个二分类问题。例如，每年都会有学生向银行申请学生贷款。一般而言，银行会根据两个因素来判定是否通过该学生贷款的申请：信用记录分数以及该学生每个月的收入。这样的话，我们可以用$X1$和$X2$分别表达学生的月收入和信用分数。然后我们可以用$Y \\in {1,0}$来表达该学生是否可以成功从银行取得贷款。Y=1表示该学生成功获得贷款，而Y=0表示该生贷款申请遭到拒绝。 假设我们有200个学生向银行申请贷款。显然，这200名学生中有人将取得贷款，而另一部分学生可能因为较差的信用分数或者较低的月收入而申请被拒。 我们可以利用逻辑回归对该问题建模。这里，$X1$和$X2$分别是一个长度为100的列向量。Y也是一个长度为200的列向量。Y中的每一个元素只可能是1或者0. First of all, the data of X1, X2, and Y are generated using some random function. 首先我们来生成X1, X2, 和Y的数据。 (It should be noted that the generation for X1, X2, and Y are kind of arbitrary as we don’t have actual data from financial institution) 这里需要声明的是，X1, X2以及Y的是随意生成的，因为我们没有实际的数据。 1234567891011121314151617181920212223242526272829303132333435363738# Add this command because of plot# Otherwise, the plot may not show up in Anaconda% matplotlib inline# Import necessary packagesimport matplotlib.pyplot as plt # Package used for plotting the figureimport numpy as np # Package relating to math# Define length of X1 vector, which is dentical to the length of X2 and Y# In total, 200 students are applying for the student loadnumber_observation = 200# Generate X1 and X2X1 = np.linspace(1600, 2500, number_observation) # Assume the students&#x27; monthly income ranges from 1600 to 2500X2 = X1/2.5 + np.random.normal(0, 100, number_observation) # Assume the credit scrore is following this function# Generate Y vectorY = np.linspace(0, 0, number_observation)# indicator represents whther the financial institution approves the student&#x27;s application or not# indicator &lt; 0 means the application is rejected.# indicator &gt;= 0 means the applcation is approved.# A noise term is added because I don&#x27;t want the data to be linearly saparableindicator = (X1 - np.mean(X1))/np.std(X1) + (X2 - np.mean(X2))/np.std(X2) + np.random.normal(0, 0.25, number_observation)Y[indicator &lt; 0] = 0Y[indicator &gt;= 0] = 1# Visualize the data pointsplt.figure(figsize=(16,8))plt.scatter(X1[indicator &lt; 0], X2[indicator &lt; 0], color=&#x27;b&#x27;, marker=&#x27;o&#x27;, label=&#x27;Rejected&#x27;)plt.scatter(X1[indicator &gt;= 0], X2[indicator &gt;= 0], color=&#x27;r&#x27;, marker=&#x27;*&#x27; , label=&#x27;Approved&#x27;)font = &#123;&#x27;family&#x27;:&#x27;Times New Roman&#x27;,&#x27;weight&#x27; : &#x27;normal&#x27;,&#x27;size&#x27;: 16,&#125;plt.xlabel(&#x27;X1&#x27;, font)plt.ylabel(&#x27;X2&#x27;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.title(&#x27;The distibution of X1 and X2&#x27;, font)plt.legend(fontsize=16)plt.show() Later we will use sigmoid function to deal with these data points. As we know, sigmoid function invovles the exponential algorithm. Since X1 is large (the maximum is about 2400), we may encounter overflow problem in coding. To avoid the overflow problem, we have to normailize X1 and X2. 在后面我们将会用sigmoid函数。这个函数包含了以自然指数e为底的运算。因为X1的数值很大，因此我们很有可能会碰到数值溢出的问题。为了避免该类问题，我们需要将X1和X2正则化。 12345678910111213141516# Normalize X1 and X2new_X1 = (X1 - np.mean(X1))/np.std(X1)new_X2 = (X2 - np.mean(X2))/np.std(X2)# Visualize the data pointsplt.figure(figsize=(16,8))plt.scatter(new_X1[indicator &lt; 0], new_X2[indicator &lt; 0], color=&#x27;b&#x27;, marker=&#x27;o&#x27;, label=&#x27;Rejected&#x27;)plt.scatter(new_X1[indicator &gt;= 0], new_X2[indicator &gt;= 0], color=&#x27;r&#x27;, marker=&#x27;*&#x27; , label=&#x27;Approved&#x27;)font = &#123;&#x27;family&#x27;:&#x27;Times New Roman&#x27;,&#x27;weight&#x27; : &#x27;normal&#x27;,&#x27;size&#x27;: 16,&#125;plt.xlabel(&#x27;new X1&#x27;, font)plt.ylabel(&#x27;new X2&#x27;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.title(&#x27;The distibution of new X1 and X2&#x27;, font)plt.legend(fontsize=16)plt.show() As we can see from the figure, the process of normalization only affects the values of X1 and X2. It doesn’t affect the distribution of X1 and X2 (the layout of X1 and X2 are still the same). 从上图可以看出，对X1和X2正则化只是影响了横纵坐标的数值大小，并不会影响数据的分布趋势。 In the figure, red stars represent the case that a student’s loan application is approved, whereas the blue dots represent the case that a student’s loan application is declined. 图中，红色五角星表示学生的贷款申请被批准；蓝色圆心表示学生的贷款申请被拒。 Although the data points are generated in an arbitrary method, these data points are consistent with our common sense. A student with higher monthly income and higher credit score tends to get approved for his appliation. In contrast, a student with low income and low credit score tends to be rejected for applying the loan. 尽管这些数据点是随意生成的，但是其符合我们的正常认知。当一个学生有较高的月收入和较高的信用分数，他将会大概率获得贷款。而当一个学生的月收入较低，信用分数也很低时，他的贷款申请将会被拒。 Now, we would like to use the sigmoid function to quantify the possibility (or probability) for a single student to get the loan. 现在我们需要用下面的这个叫做sigmoid的函数来表征单个学生能够拿到贷款的概率: $h^i(X_1, X_2) = \\frac{e^{\\beta_1 X_1^i + \\beta_2 X_2^i}}{1 + e^{\\beta_1 X_1^i + \\beta_2 X_2^i}}$ where the superscript $i$ represents the $i^{th}$ student. 式中上标$i$表示第$i$个学生。 The question is then how to determine the two parameters: $\\beta_1$ and $\\beta_2$ 现在的问题便是如何确定$\\beta_1$和$\\beta_2$的数值。 As what we did in week 1 Linear regression, we need to introduce an objective function (loss function). Then we use gradient descent to find the global minimum of the objective function. 正如我们在第一周线性回归中讲述的一样，我们需要引入一个目标函数（损失函数）。然后我们利用梯度下降方法来寻找目标函数的最小值。 The objective function is listed below and it is revised from the maximum likelihood function of logistic regression: 目标函数定义如下，它是基于逻辑回归的最大似然函数修改得到的： $L(\\beta_1, \\beta_2) = -\\frac{1}{N}\\sum_{i=0}^N{y^i ln[h^i(X_1^i, X_2^i)]+(1-y^i) ln[1-h(X_1^i, X_2^i)]}$ The plot for the objective function is shown below: 该目标函数图象如下所示： 12345678910111213141516171819202122232425262728293031323334353637# Import the package for three-dimensional plotfrom mpl_toolkits.mplot3d import Axes3D# Generate values for beta_1 and beta_2number_beta = 100beta_1 = np.linspace(2, 8, number_beta)beta_2 = np.linspace(1, 8, number_beta)# Initialize a matrix to store loss function valuesloss = np.zeros([number_beta, number_beta])# Initialize a matrix to store grid valuesgrid_beta_1 = np.zeros([number_beta, number_beta])grid_beta_2 = np.zeros([number_beta, number_beta])# Calculate the loss function values under different beta_1 and beta_2for i in range(number_beta): for j in range(number_beta): grid_beta_1[i,j] = beta_1[i] grid_beta_2[i,j] = beta_2[j] s = 0 for indx in range(number_observation): h = np.exp(new_X1[indx] * beta_1[i] + new_X2[indx] * beta_2[j]) / (1+np.exp(new_X1[indx] * beta_1[i] + new_X2[indx] * beta_2[j])) temp = Y[indx]*np.log(h) + (1-Y[indx])*np.log(1-h) s = s + temp loss[i,j] = -1/number_observation * s # Plot the loss function values over the beta_0 and beta_1 valuesfig = plt.figure(figsize=(16,8))ax = Axes3D(fig)ax.set_xlabel(r&quot;$\\beta_1$&quot;, font)ax.set_ylabel(r&quot;$\\beta_2$&quot;, font)ax.set_zlabel(&quot;Loss function value&quot;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)ax.plot_surface(grid_beta_1, grid_beta_2, loss, cmap=&#x27;rainbow&#x27;)plt.show() From the figure above, the objective function has a global minimum and we are trying to find this global minimum. Again we will use gradient descent to reach our target. 从上图可以看出，目标函数是有全局最小值的。我们会用梯度下降的方法来寻找该最小值。 Let’s calculate the derivate for the objective function. 先来计算目标函数关于$\\beta_1$和$\\beta_2$的导数。 $\\frac{\\partial L(\\beta_1,\\beta_2)}{\\partial \\beta_1}= -\\frac{1}{N}\\sum_{i=1}^N {y^i \\frac{1}{h^i} (h^i)’ + (1-y^i \\frac{1}{1-h^i} (-h^i)’}$ $=-\\frac{1}{N}\\sum_{i=1}^N {\\frac{y^i}{h^i} - \\frac{(1-y^i)}{1-h^i}} (h^i)’$ $=-\\frac{1}{N}\\sum_{i=1}^N {\\frac{y^i}{h^i} - \\frac{(1-y^i)}{1-h^i}} h^i (1-h^i) x_1^i$ $=-\\frac{1}{N}\\sum_{i=1}^N {y^i - h^i}x_1^i$ $\\frac{\\partial L(\\beta_1,\\beta_2)}{\\partial \\beta_2}= -\\frac{1}{N}\\sum_{i=1}^N {y^i \\frac{1}{h^i} (h^i)’ + (1-y^i \\frac{1}{1-h^i} (-h^i)’}$ $=-\\frac{1}{N}\\sum_{i=1}^N {\\frac{y^i}{h^i} - \\frac{(1-y^i)}{1-h^i}} (h^i)’$ $=-\\frac{1}{N}\\sum_{i=1}^N {\\frac{y^i}{h^i} - \\frac{(1-y^i)}{1-h^i}} h^i (1-h^i) x_2^i$ $=-\\frac{1}{N}\\sum_{i=1}^N {y^i - h^i}x_2^i$ Where the superscript $i$ means the $i^{th}$ element in X1, X2, or Y. $h$ is just shorthand for $h(X1, X2)$ 上式中，上标$i$表示X1，X2或者Y中的第$i$个元素。$h$是$h(X1,X2)$的简写。 Then we can use the negative gradient direction to update the two parameters: 接下来我们可以用负梯度方向来更新两个参数： $\\beta_1^{n+1} = \\beta_1^n - s\\frac{\\partial L(\\beta_1^n, \\beta_2^n)}{\\partial \\beta_1^n}$ $\\beta_2^{n+1} = \\beta_2^n - s\\frac{\\partial L(\\beta_1^n, \\beta_2^n)}{\\partial \\beta_2^n}$ First of all, let’s arbitrarily give two initial values to $\\beta_1$ and $\\beta_2$ and visualize the classification boundary. 首先我们先给$\\beta_1$和$\\beta_2$任意赋两个初始值，然后画出区分边界。 The boundary line is drawn using the following equation: 边界的直线由下面的等式来确定： $\\beta_1 xx + \\beta_2 yy = 0$ It should be noted that xx and yy here only refers to the coordinates of horizontal or vertical axes. They don’t refer to any predictor or response mentioned in the backgroun section. They are used for plotting the boundary only. No special meanings! Don’t get confused! $\\beta_1$ and $\\beta_2$ are two parameters of our interest, both of which are obtained from gradient descent algorithm. 需要注意的是，上面等式里面的xx和yy仅仅指二维坐标系中的坐标值，仅作画边界直线用，与问题背景交代中的x和y没有任何关系。不要混淆了。$\\beta_1$和$\\beta_2$是我们所感兴趣的参数，由梯度下降得到。 123456789101112131415161718192021# Two arbitrary values for beta_1 and beta_2beta_1 = 0.1beta_2 = 0.6# Get the boundaryxx = np.linspace(-2, 2, 100)yy = -beta_1 * xx / beta_2# Plot the data points and boundary line at initial beta_0 and beta_1fig = plt.figure(figsize=(16,8))plt.scatter(new_X1[indicator &lt; 0], new_X2[indicator &lt; 0], color=&#x27;b&#x27;, marker=&#x27;o&#x27;, label=&#x27;Rejected&#x27;)plt.scatter(new_X1[indicator &gt;= 0], new_X2[indicator &gt;= 0], color=&#x27;r&#x27;, marker=&#x27;*&#x27; , label=&#x27;Approved&#x27;)plt.plot(xx, yy, label=&#x27;Boundary&#x27;)font = &#123;&#x27;family&#x27;:&#x27;Times New Roman&#x27;,&#x27;weight&#x27; : &#x27;normal&#x27;,&#x27;size&#x27;: 16,&#125;plt.xlabel(&#x27;new X1&#x27;, font)plt.ylabel(&#x27;new X2&#x27;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.title(&#x27;The distibution of new X1 and X2&#x27;, font)plt.legend(fontsize=16)plt.show() Not surprisingly, the line does not classify two types of data points well. 随意给出的这条直线并不能很好的划分两类数据点。 Now let’s use gradient descent to update $\\beta_1$ and $\\beta_2$. 现在用梯度下降的方法来更新$\\beta_1$和$\\beta_2$的数值： 12345678910111213141516171819202122232425262728# Assume we are going to iterate 1000 timesmax_iteration = 3000# Define step sizestep_size = 0.0001# Initialize beta_1, beta_2, and loss to track the update algorithmbeta_1_update = np.zeros([max_iteration+1, 1])beta_2_update = np.zeros([max_iteration+1, 1])loss_update = np.zeros([max_iteration+1, 1])# Initial value for beta_1 and beta_2beta_1_update[0,0] = beta_1beta_2_update[0,0] = beta_2# Iterate many times in order to get the best values for beta_0 and beta_1for iter in range(max_iteration): # Calculate h function results h = np.exp(new_X1 * beta_1_update[iter,0] + new_X2 * beta_2_update[iter,0]) / (1 + np.exp(new_X1 * beta_1_update[iter,0] + new_X2 * beta_2_update[iter,0])) # Calculate the loss function value loss_update[iter,0] = -np.mean(Y * np.log(h) + (1-Y) * np.log(1-h)) # Calculate the gradient gradient_beta_1 = -np.sum((Y-h) * X1)/number_observation gradient_beta_2 = -np.sum((Y-h) * X2)/number_observation # Update beta_1 and beta_2 beta_1_update[iter+1] = beta_1_update[iter] - step_size * gradient_beta_1 beta_2_update[iter+1] = beta_2_update[iter] - step_size * gradient_beta_2 1234567891011# Plot the loss vs. iteration timesplt.figure(figsize=(16,8))plt.plot(range(max_iteration), loss_update[0:max_iteration,0], color=&#x27;g&#x27;, linewidth=2.0, label=&#x27;fitted line&#x27;)font = &#123;&#x27;family&#x27;:&#x27;Times New Roman&#x27;,&#x27;weight&#x27; : &#x27;normal&#x27;,&#x27;size&#x27;: 16,&#125;plt.xlabel(&#x27;iteration times&#x27;, font)plt.ylabel(&#x27;loss function values&#x27;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.title(&#x27;Loss function value vs. iteration times&#x27;, font)plt.legend(fontsize=16)plt.show() As shown in the figure above, the loss already reaches convergence, which means increasing the iteration times would not further decrease the loss. 从上图可以看出，损失值已达到收敛。这意味着进一步增加迭代次数不会减少损失值。 The final boundary and data points are shown below: 最终的边界如下图所示： 12345678910111213141516# Plot the data points and boundary line at final beta_0 and beta_1xx = np.linspace(-2, 2, 100)yy = -beta_1_update[-1,0] * xx / beta_2_update[-1,0]fig = plt.figure(figsize=(16,8))plt.scatter(new_X1[indicator &lt; 0], new_X2[indicator &lt; 0], color=&#x27;b&#x27;, marker=&#x27;o&#x27;, label=&#x27;Rejected&#x27;)plt.scatter(new_X1[indicator &gt;= 0], new_X2[indicator &gt;= 0], color=&#x27;r&#x27;, marker=&#x27;*&#x27; , label=&#x27;Approved&#x27;)plt.plot(xx, yy, label=&#x27;Final boundary&#x27;)font = &#123;&#x27;family&#x27;:&#x27;Times New Roman&#x27;,&#x27;weight&#x27; : &#x27;normal&#x27;,&#x27;size&#x27;: 16,&#125;plt.xlabel(&#x27;new X1&#x27;, font)plt.ylabel(&#x27;new X2&#x27;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.title(&#x27;The distibution of new X1 and X2&#x27;, font)plt.legend(fontsize=16)plt.show() As shwon in the figure above, the boundary separates the blue dots and red stars. Although there are some mis-classification points, these mis-classifications are inevitable as the original data points are not linear separable. 如上图所示，最终的边界直线可以较好的区分蓝色圆点和红色星状点。尽管有一些数据点没有被正确的划分，这种“错误”是无法避免的，因为我们原始的数据并不是被线性函数完全分割的(即两类数据点相互侵入对方区域)。 ———————————– end —————————————————- Review (往期回顾): Week 1 Linear regression (线性回归)https://blog.csdn.net/weixin_42515443/article/details/80768841","categories":[{"name":"Blog","slug":"Blog","permalink":"http://example.com/categories/Blog/"}],"tags":[]},{"title":"Week 1 Linear Regression","slug":"Week-1-Linear-Regression","date":"2021-03-09T07:34:05.000Z","updated":"2021-03-09T18:30:47.749Z","comments":true,"path":"2021/03/08/Week-1-Linear-Regression/","link":"","permalink":"http://example.com/2021/03/08/Week-1-Linear-Regression/","excerpt":"","text":"I have been learning the statistics for about one year. Nine months ago, I didn’t believe that I can survive from statistics classes as I don’t know much about statistics. For example, I don’t even know that Gaussian distribution is another name of Normal distribution. I just want write something here to summarize what I have learned during this year. 统计学也陆陆续续的学了一年了。没想到自己除了土木工程还是可以学一些其他的东西。现在利用暑假总结一下自己这一年学过的统计学知识，也算是对自己统计学的辅修有一个交代。 What I am writing here is something I summarized using my own words. These “words” may not be accurate enough as I am an Engineering student, not a student majoring in statistics. I just wrote all this stuff based on my own interest. I hope this note could help someone who doesn’t has much background in statistics but wants to learn some statistics. 这些所写的内容都是基于我自己的理解，里面所用到的一些词语并不是非常准确。毕竟是我只是一个工程学科的学生，不是一个统计学学生。我写下这些东西也只是基于自己的兴趣爱好，同时希望帮助一些像我一样零基础的同学学习统计学。 ———————————————– starts from here ——————————————————— Background (问题背景): Assume that both X and Y are a N by 1 vector. X is called as predictor and Y is called as response. 假定X和Y均是一个N行1列的向量（矩阵）。X被称作自变量，Y被称作因变量。 The relationship between X and Y is presented in the figure below (python code is provided): X与Y之间的关系见下图所示 (python源代码也附在下面)： 123456789101112131415161718192021# Add this command in order to show the plot in Anaconda# Otherwise the plot may not show up% matplotlib inline# Import necessary packagesimport matplotlib.pyplot as plt # Package used for plotting the figureimport numpy as np # Package for matrix operation# Define the number of observation# This number is also the length of X or Y vectornumber_observation = 1000# Generate X using linear space, i.e., X increase from -5 to 5. The interval is a constant such that there will be 1000 X.X = np.linspace(-5, 5, number_observation)# Generate Y# Assume Y is generated using the equation: Y = 2X + 3 + e# e refers to the noise, which may be caused by measurement error.# e is assumed to follow normal distribution with a mean of 0 and a standard deviation of 1e = np.random.normal(0, 1, number_observation)Y = 2*X + 3 + e 12345678910# Plot the X and Yplt.figure(figsize=(16,8))plt.scatter(X, Y, color=&#x27;r&#x27;)font = &#123;&#x27;family&#x27;:&#x27;Times New Roman&#x27;,&#x27;weight&#x27; : &#x27;normal&#x27;,&#x27;size&#x27;: 16,&#125;plt.xlabel(&#x27;X&#x27;, font)plt.ylabel(&#x27;Y&#x27;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.title(&#x27;The relationship between X and Y&#x27;, font)plt.show() Now we roughly know the relationship between X and Y. It seems that Y is linearly dependent on X. Therefore we try to use a linear function to fit these data points. 现在我们大致了解X与Y之间的关系。通过图可以看出，Y似乎和X呈现出一种线性关系。因此我们需要用线性函数来拟合这些离散的数据点。 The linear function is presented below: 线性函数的形式如下所示： $h(x_i)=\\beta_1 X_i + \\beta_0$ Where $h(x_i)$ is the predicted response when $x_i$ is given. 函数中，$h(x_i)$是当给定$X_i$值时，预测的Y值。 Now, we only need to determine the values for $\\beta_1$ and $\\beta_0$ such that $h(x_i)$ is close to $Y_i$ as much as possible. 现在，我们需要确定$\\beta_1$和$\\beta_0$的值，使得我们预测出的每一个 $h(x_i)$都尽可能的接近真实值$y_i$. Therefore, we need to create a indicator to quantify how close the predicted response is close to actual response. The mean squared error loss function is used here as the indicator: 因此我们需要建立一个量化指标来衡量到底预测值$h(x_i)$与真实值$y_i$有多接近。我们将使用平方和损失函数（目标函数）作为这个量化指标： $L(\\beta_0, \\beta_1) = \\frac{1}{N}\\sum_{i=1}^N(\\beta_0+\\beta_1 x_i - y_i)^2$ Based on this loss function, we try to find optimized values for $\\beta_0$ and $\\beta_1$ such that the loss is minimized. 借助于这个损失函数，我们试图寻找$\\beta_0$和$\\beta_1$的最优解，在这个最优解下，损失函数的值最小。 If this problem is solved manually, we can just take the derivative of the loss function with respect to $\\beta_1$ or $\\beta_0$. In this case, we can obtain the optimized values directly. 如果我们试图用手算来解决这个问题，我们可以直接将损失函数对$\\beta_0$和$\\beta_1$求导数，即可获得$\\beta_0$和$\\beta_1$的解。 Here, we would like to solve this problem using computer programming. Therefore, optimization algorith gradient descent is involved. 这里，我们想写计算机代码来解决这个问题，因此我们要用到叫做“梯度下降”的优化算法。 Graident descent will be introduced later in this session. 梯度下降的算法将会在稍后进行介绍。 The plot for the loss function is presented below (python code is also provided): 平方和损失函数如下图所示（python源代码一并提供）： 12345678910111213141516171819202122232425262728293031323334353637# Import the package for three-dimensional plotfrom mpl_toolkits.mplot3d import Axes3D# Generate values for beta_0 and beta_1number_beta = 100beta_0 = np.linspace(-5, 10, number_beta)beta_1 = np.linspace(-1, 5, number_beta)# Create a grid to evaluate loss function values on the grid# You can either use command in line #11 or comand in line #18, 19, 23, 24 to create grid# grid_beta_0, grid_beta_1 = np.meshgrid(beta_0, beta_1)# Calculate the loss function values under different beta_0 and beta_1# Initialize a matrix to store loss function valuesloss = np.zeros([number_beta, number_beta])# Initialize a matrix to store grid valuesgrid_beta_0 = np.zeros([number_beta, number_beta])grid_beta_1 = np.zeros([number_beta, number_beta])for i in range(number_beta): for j in range(number_beta): grid_beta_0[i,j] = beta_0[i] grid_beta_1[i,j] = beta_1[j] predict_response = beta_0[i] + beta_1[j] * X loss[i,j] = np.dot((predict_response - Y).T, (predict_response-Y))/number_observation# Plot the loss function values over the beta_0 and beta_1 valuesfig = plt.figure(figsize=(16,8))ax = Axes3D(fig)ax.set_xlabel(r&quot;$\\beta_0$&quot;, font)ax.set_ylabel(r&quot;$\\beta_1$&quot;, font)ax.set_zlabel(&quot;Loss function value&quot;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)ax.plot_surface(grid_beta_0, grid_beta_1, loss, cmap=&#x27;rainbow&#x27;)plt.show() The figure above shows that a global minimum exists for this loss function. This global minimum is the case that we want to achieve because the loss is smallest. In other words, the predicted response is closest to the actual response. 上图展示了我们损失函数有一个全局最小值，而这个最小值正是我们试图寻找的。该最小值表征了我们预测的Y值与真实Y值是最接近的。 As mentioned above, we are using gradient descent to find the global minimum. For those who are not familiar with gradient descent, please refer to the following link for more information: https://en.wikipedia.org/wiki/Gradient_descent 如上文提到的，我们将使用梯度下降方法来寻找全局最小值。对于还不是很熟悉梯度下降概念的同学，可以点击下面链接来了解梯度下降方法： https://baike.baidu.com/item/梯度下降/4864937?fr=aladdin For gradient descent algorithm, the first step is to give arbitary values for $\\beta_0$ and $\\beta_1$. 梯度下降方法中，我们先随机赋予$\\beta_0$和$\\beta_1$两个数值。 123456789101112131415161718# These two values are given arbitrarily# You can give any values as you likebeta_0 = 1beta_1 = 0.5predict_response = beta_0 + beta_1 * X# Visualize the fitted lineplt.figure(figsize=(16,8))plt.scatter(X, Y, color=&#x27;r&#x27;, label=&#x27;original data points&#x27;)plt.plot(X, predict_response, color=&#x27;g&#x27;, linewidth=2.0, label=&#x27;fitted line&#x27;)font = &#123;&#x27;family&#x27;:&#x27;Times New Roman&#x27;,&#x27;weight&#x27; : &#x27;normal&#x27;,&#x27;size&#x27;: 16,&#125;plt.xlabel(&#x27;X&#x27;, font)plt.ylabel(&#x27;Y&#x27;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.title(&#x27;Original data points and fitted line&#x27;, font)plt.legend(fontsize=16)plt.show() As shown in the figure above, the initial fitted line does not match the data points. This is not surprised as the values of $\\beta_0$ and $\\beta_1$ are given arbritarily. 上图展示了拟合的直线与离散的数据点吻合并不是很好。这并不出乎意料，因为我们只是随意的给$\\beta_0$和$\\beta_1$赋值。 Don’t worry, we will use gradient descent to “train” $\\beta_0$ and $\\beta_1$. Eventually, a good fitted line will be obtained. 我们会用梯度下降来“训练”$\\beta_0$和$\\beta_1$，使得最终获得的较好的拟合效果。 We need to find the gradient of the loss function, i.e., the derivative with respect to $\\beta_0$ and $\\beta_1$: 首先，我们需要寻找函数的“梯度”，即关于$\\beta_0$和$\\beta_1$的导数： $\\frac{\\partial L(\\beta_0,\\beta_1)}{\\partial \\beta_0} = \\frac{2}{N}\\sum_{i=1}^{N}(\\beta_0 + \\beta_1 x_i - y_i)$ $\\frac{\\partial L(\\beta_0,\\beta_1)}{\\partial \\beta_1} = \\frac{2}{N}\\sum_{i=1}^{N}(\\beta_0 + \\beta_1 x_i - y_i)x_i$ Then we just need to use the negative gradient direction to update $\\beta_0$ and $beta_1$ 然后，我们沿着梯度的负方向来迭代更新$\\beta_0$和$\\beta_1$两个参数。 $\\beta_0^{n+1} = \\beta_0^n - s\\frac{\\partial L(\\beta_0^n, \\beta_1^n)}{\\partial \\beta_0^n}$ $\\beta_1^{n+1} = \\beta_1^n - s\\frac{\\partial L(\\beta_0^n, \\beta_1^n)}{\\partial \\beta_1^n}$ where s is the step size. Step size cannot be neither too large nor too small. If it is too large, then we may miss the global minimum value. If it is too small, this update algorithm would be time-consuming. 表达式中的s是代表步长。步长不能太长，也不能太短。步长如果太长，会使得我们错过了全局最小值。如果步长太短，会使得算法花很长的时间来收敛。 Then the question is how to determine the value for step size. Honestly, I don’t know the answer. Evertime I did this. I always given an arbitrary value for the step size. If it doesn’t work well, then I just change the value for step size, and try again. It’s like a trial and error process. 那么如何确定步长的大小。这是一个“玄学”。至少我本人不是很了解如何确定。我通常的做法是给定一个步长，跑整个程序。如果结果不好，我再修改步长，再运行，直到结果比较满意为止。 The following section gives the code on how we perform gradience descent algorithm. The final results are also shown below. 接下来的代码展示了我们如何使用梯度下降方法。最终结果也一并画图呈现。 12345678910111213141516171819202122232425# Assume we are going to iterate 5000 timesmax_iteration = 5000# Assume step size is 0.001step_size = 0.001# Initialize beta_0, beta_1, and loss to track the update algorithmbeta_0_update = np.zeros([max_iteration+1, 1])beta_1_update = np.zeros([max_iteration+1, 1])loss_update = np.zeros([max_iteration+1, 1])# Initial value for beta_0 and beta_1beta_0_update[0,0] = beta_0beta_1_update[0,0] = beta_1# Iterate many times in order to get the best values for beta_0 and beta_1for iter in range(max_iteration): predict_response = beta_0_update[iter,0] + beta_1_update[iter,0] * X difference = predict_response - Y loss_update[iter,0] = np.dot(difference.T, difference)/number_observation gradient_beta_0 = 2 * np.sum(difference)/number_observation gradient_beta_1 = 2 * np.dot(difference, X)/number_observation beta_0_update[iter+1] = beta_0_update[iter] - step_size * gradient_beta_0 beta_1_update[iter+1] = beta_1_update[iter] - step_size * gradient_beta_1 12345678910111213Y_predict = beta_0_update[-1,0]+ beta_1_update[-1,0] * Xplt.figure(figsize=(16,8))plt.scatter(X, Y, color=&#x27;r&#x27;, label=&#x27;original data points&#x27;)plt.plot(X, Y_predict, color=&#x27;g&#x27;, linewidth=2.0, label=&#x27;fitted line&#x27;)font = &#123;&#x27;family&#x27;:&#x27;Times New Roman&#x27;,&#x27;weight&#x27; : &#x27;normal&#x27;,&#x27;size&#x27;: 16,&#125;plt.xlabel(&#x27;X&#x27;, font)plt.ylabel(&#x27;Y&#x27;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.title(&#x27;Original data points and final fitted line&#x27;, font)plt.legend(fontsize=16)plt.show() 12345678910plt.figure(figsize=(16,8))plt.plot(range(max_iteration), loss_update[0:max_iteration,0], color=&#x27;g&#x27;, linewidth=2.0, label=&#x27;fitted line&#x27;)font = &#123;&#x27;family&#x27;:&#x27;Times New Roman&#x27;,&#x27;weight&#x27; : &#x27;normal&#x27;,&#x27;size&#x27;: 16,&#125;plt.xlabel(&#x27;iteration times&#x27;, font)plt.ylabel(&#x27;loss function values&#x27;, font)plt.xticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.yticks(fontsize=16, fontname=&#x27;Times New Roman&#x27;)plt.title(&#x27;Loss function value vs. iteration times&#x27;, font)plt.legend(fontsize=16)plt.show() As observed from the plot of loss function value vs. iteration times, the loss already reaches convergence. This means that even we increase the iteration times, the loss would not further decrease. The final fitted line and data points are shown in the figure above. 从损失函数与迭代次数的关系图象可以看出，损失函数早已收敛。这意味着，即便我们增加迭代次数，损失函数的值不会进一步减小。最终拟合曲线与离散点在上文的图也已展示。 OK. We are done. Feel free to leave any comments. 到此结束。","categories":[{"name":"Blog","slug":"Blog","permalink":"http://example.com/categories/Blog/"}],"tags":[]},{"title":"test_my_site","slug":"test-my-site","date":"2021-03-07T06:32:22.000Z","updated":"2021-03-07T06:32:22.840Z","comments":true,"path":"2021/03/06/test-my-site/","link":"","permalink":"http://example.com/2021/03/06/test-my-site/","excerpt":"","text":"","categories":[],"tags":[]}],"categories":[{"name":"Blog","slug":"Blog","permalink":"http://example.com/categories/Blog/"}],"tags":[{"name":"news","slug":"news","permalink":"http://example.com/tags/news/"}]}